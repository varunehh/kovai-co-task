{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b89dcfb",
   "metadata": {},
   "source": [
    "**Step 1: Environment Setup & Data Preparation**\n",
    "\n",
    "This block handles the initial setup. It imports necessary libraries, creates directories for organizing outputs (`charts/` and `dashboard_data/`), loads the dataset, standardizes the date format, and fills missing values using linear interpolation to ensure a continuous time series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19662b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 Complete: Data loaded, cleaned, and imputed.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# --- 1. Setup Directories & Settings ---\n",
    "# Create folders to store charts and dashboard logs\n",
    "os.makedirs('charts', exist_ok=True)\n",
    "os.makedirs('dashboard_data', exist_ok=True)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 2. Data Loading ---\n",
    "file_path = \"Daily_Public_Transport_Passenger_Journeys_by_Service_Type_20250603.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Standardize 'Date' and set as index\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y', errors='coerce')\n",
    "df = df.set_index('Date').sort_index()\n",
    "\n",
    "# --- 3. Imputation Strategy ---\n",
    "# Use Linear Interpolation to fill small gaps while preserving trends\n",
    "df['Other'] = df['Other'].interpolate(method='linear').fillna(0)\n",
    "\n",
    "# Calculate 'Total Journeys' (Sum of all service types)\n",
    "df['Total Journeys'] = df[['Local Route', 'Light Rail', 'Peak Service', 'Rapid Route', 'School', 'Other']].sum(axis=1)\n",
    "\n",
    "print(\"Step 1 Complete: Data loaded, cleaned, and imputed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11f52a3",
   "metadata": {},
   "source": [
    "**Step 2: Exploratory Data Analysis (EDA)**\n",
    "\n",
    "This block calculates the 5 key insights (Service Type split, Weekly Seasonality, School Impact, etc.), generates visualizations for each using matplotlib, and saves the underlying data to CSV files for your future dashboard.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5969552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2 Complete: EDA charts saved to 'charts/' and logs to 'dashboard_data/'.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Insight 1: Ridership by Service Type ---\n",
    "total_journeys = (df[['Local Route', 'Light Rail', 'Peak Service', 'Rapid Route', 'School', 'Other']].sum() / 1000000).sort_values(ascending=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "total_journeys.plot(kind='barh', color='skyblue')\n",
    "plt.title('Total Passenger Journeys by Service Type (Millions)')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('charts/insight1_service_types.png')\n",
    "plt.close()\n",
    "# Save log\n",
    "total_journeys.to_csv('dashboard_data/log_insight1_services.csv')\n",
    "\n",
    "# --- Insight 2: Weekly Seasonality ---\n",
    "df['DayOfWeek'] = df.index.day_name()\n",
    "day_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "avg_journeys = df.groupby('DayOfWeek')['Total Journeys'].mean().reindex(day_order)\n",
    "\n",
    "plt.figure(figsize=(9, 5))\n",
    "avg_journeys.plot(kind='bar', color='darkorange')\n",
    "plt.title('Average Daily Journeys by Day of Week')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.savefig('charts/insight2_dayofweek.png')\n",
    "plt.close()\n",
    "# Save log\n",
    "avg_journeys.to_csv('dashboard_data/log_insight2_dayofweek.csv')\n",
    "\n",
    "# --- Insight 3: School Ridership Share ---\n",
    "school_total = df['School'].sum()\n",
    "total_all = df['Total Journeys'].sum()\n",
    "school_impact = pd.Series({'School': school_total, 'Public': total_all - school_total})\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(school_impact, labels=school_impact.index, autopct='%1.1f%%', startangle=90, colors=['gold', 'lightgray'])\n",
    "plt.title('School vs. Public Ridership Share')\n",
    "plt.savefig('charts/insight3_school_impact.png')\n",
    "plt.close()\n",
    "# Save log\n",
    "school_impact.to_csv('dashboard_data/log_insight3_school.csv')\n",
    "\n",
    "# --- Insight 4: Yearly Trend ---\n",
    "yearly_trend = df['Total Journeys'].resample('Y').sum() / 1000000\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(yearly_trend.index.year, yearly_trend.values, marker='o', color='green')\n",
    "plt.title('Annual Ridership Trend (Millions)')\n",
    "plt.grid(True, linestyle='--', alpha=0.6)\n",
    "plt.tight_layout()\n",
    "plt.savefig('charts/insight4_yearly_trend.png')\n",
    "plt.close()\n",
    "# Save log\n",
    "yearly_trend.to_csv('dashboard_data/log_insight4_trend.csv')\n",
    "\n",
    "print(\"Step 2 Complete: EDA charts saved to 'charts/' and logs to 'dashboard_data/'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afc0062",
   "metadata": {},
   "source": [
    "**Step 3: Multi-Model Forecasting (Prophet, SARIMA, LightGBM)**\n",
    "\n",
    "This block generates the official 7-day forecast using three different algorithms:\n",
    "\n",
    "- **Prophet:** Good for seasonality and holidays.  \n",
    "- **SARIMA:** Statistical method excellent for short-term patterns.  \n",
    "- **LightGBM:** A powerful machine learning model (added as requested).\n",
    "\n",
    "It saves the forecast results for all three models to separate CSV files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bbc8a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Step 3: Generating 7-Day Forecasts (3 Models) ---\n",
      "Processing Local Route...\n",
      "Processing Light Rail...\n",
      "Processing Peak Service...\n",
      "Processing Rapid Route...\n",
      "Processing School...\n",
      "Forecasts generated successfully.\n"
     ]
    }
   ],
   "source": [
    "from prophet import Prophet\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import numpy as np\n",
    "\n",
    "# --- Helper: Metrics Calculation ---\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculates RMSE, MAE, MAPE, and SMAPE.\"\"\"\n",
    "    y_true, y_pred = np.array(y_true, dtype=float), np.array(y_pred, dtype=float)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "    # SMAPE: Symmetric Mean Absolute Percentage Error\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    smape = np.mean(np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator!=0)) * 100\n",
    "    \n",
    "    return {'RMSE': rmse, 'MAE': mae, 'MAPE': mape, 'SMAPE': smape}\n",
    "\n",
    "# --- Helper: LightGBM Feature Engineering ---\n",
    "def create_features(data, label=None):\n",
    "    X = data.copy()\n",
    "    X['dayofweek'] = X.index.dayofweek\n",
    "    X['month'] = X.index.month\n",
    "    X['year'] = X.index.year\n",
    "    X['dayofyear'] = X.index.dayofyear\n",
    "    X['lag_7'] = X[label].shift(7)\n",
    "    X['lag_14'] = X[label].shift(14)\n",
    "    X['roll_mean_7'] = X[label].shift(7).rolling(window=7).mean()\n",
    "    return X.dropna()\n",
    "\n",
    "service_types = ['Local Route', 'Light Rail', 'Peak Service', 'Rapid Route', 'School']\n",
    "start_date = df.index.max() + pd.Timedelta(days=1)\n",
    "end_date = df.index.max() + pd.Timedelta(days=7)\n",
    "future_range = pd.date_range(start_date, end_date, freq='D')\n",
    "\n",
    "# Initialize Forecast DataFrames\n",
    "forecast_p = pd.DataFrame({'Date': future_range}).set_index('Date')\n",
    "forecast_s = pd.DataFrame({'Date': future_range}).set_index('Date')\n",
    "forecast_l = pd.DataFrame({'Date': future_range}).set_index('Date')\n",
    "\n",
    "print(\"--- Step 3: Generating 7-Day Forecasts (3 Models) ---\")\n",
    "\n",
    "for service in service_types:\n",
    "    print(f\"Processing {service}...\")\n",
    "    ts = df[service].astype(float)\n",
    "    \n",
    "    # --- MODEL A: PROPHET ---\n",
    "    df_p = pd.DataFrame({'ds': ts.index, 'y': ts.values})\n",
    "    m_p = Prophet(growth='linear', seasonality_mode='multiplicative', weekly_seasonality=True)\n",
    "    m_p.fit(df_p)\n",
    "    # Forecast\n",
    "    future_p = m_p.make_future_dataframe(periods=7, include_history=False)\n",
    "    pred_p = m_p.predict(future_p)['yhat'].clip(lower=0).round(0).astype(int)\n",
    "    forecast_p[service] = pred_p.values\n",
    "\n",
    "    # --- MODEL B: SARIMA ---\n",
    "    try:\n",
    "        m_s = SARIMAX(ts, order=(1, 1, 1), seasonal_order=(0, 1, 1, 7), \n",
    "                      enforce_stationarity=False, enforce_invertibility=False)\n",
    "        res_s = m_s.fit(disp=False)\n",
    "        pred_s = res_s.predict(start=start_date, end=end_date).clip(lower=0).round(0).astype(int)\n",
    "        forecast_s[service] = pred_s.values\n",
    "    except:\n",
    "        forecast_s[service] = 0\n",
    "    \n",
    "    # --- MODEL C: LIGHTGBM ---\n",
    "    df_lgb = create_features(pd.DataFrame(ts), label=service)\n",
    "    X_train = df_lgb.drop(columns=[service])\n",
    "    y_train = df_lgb[service]\n",
    "    \n",
    "    model_lgb = lgb.LGBMRegressor(objective='regression', n_estimators=100, learning_rate=0.1, verbose=-1)\n",
    "    model_lgb.fit(X_train, y_train)\n",
    "    \n",
    "    # Future features construction\n",
    "    future_feats = []\n",
    "    for date in future_range:\n",
    "        hist_date = date - pd.Timedelta(days=7)\n",
    "        lag_val = ts.loc[hist_date] if hist_date in ts.index else 0\n",
    "        lag_14_val = ts.loc[date - pd.Timedelta(days=14)] if (date - pd.Timedelta(days=14)) in ts.index else 0\n",
    "        roll_mean = ts.loc[date - pd.Timedelta(days=13):hist_date].mean()\n",
    "        future_feats.append({\n",
    "            'dayofweek': date.dayofweek, 'month': date.month, \n",
    "            'year': date.year, 'dayofyear': date.dayofyear,\n",
    "            'lag_7': lag_val, 'lag_14': lag_14_val, 'roll_mean_7': roll_mean\n",
    "        })\n",
    "    \n",
    "    X_future = pd.DataFrame(future_feats)[X_train.columns]\n",
    "    pred_l = model_lgb.predict(X_future)\n",
    "    forecast_l[service] = pred_l.clip(min=0).round(0).astype(int)\n",
    "\n",
    "# Save Logs\n",
    "forecast_p.to_csv('dashboard_data/log_forecast_prophet.csv')\n",
    "forecast_s.to_csv('dashboard_data/log_forecast_sarima.csv')\n",
    "forecast_l.to_csv('dashboard_data/log_forecast_lightgbm.csv')\n",
    "\n",
    "print(\"Forecasts generated successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9b5c23",
   "metadata": {},
   "source": [
    "**Step 4: Final Model Comparison (Detailed Backtesting)**\n",
    "\n",
    "This block performs the rigorous \"Face-Off\" on the last 7 days of known data, evaluating models with multiple error metrics:\n",
    "\n",
    "- **MAE:** Mean Absolute Error  \n",
    "- **RMSE:** Root Mean Squared Error  \n",
    "- **MAPE:** Mean Absolute Percentage Error  \n",
    "- **SMAPE:** Symmetric MAPE  \n",
    "\n",
    "- **Consolidated Results:** Saved as `log_model_comparison_full.csv`.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ac1b15c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step 4: Final Model Comparison (Backtesting with Advanced Metrics) ---\n",
      "Evaluating forecast accuracy on the last 7 days of known data...\n",
      "\n",
      "Service         | Model      | MAE      | RMSE     | MAPE     | SMAPE   \n",
      "---------------------------------------------------------------------------\n",
      "Local Route     | Prophet    | 10236    | 11838    | 998.98   | 199.11  \n",
      "                | SARIMA     | 9182     | 10684    | 848.99   | 199.35  \n",
      "                | LightGBM   | 9171     | 10674    | 815.23   | 199.27  \n",
      "---------------------------------------------------------------------------\n",
      "Light Rail      | Prophet    | 8272     | 8628     | 26036373726048940032.00 | 189.53  \n",
      "                | SARIMA     | 5307     | 5935     | 15834479632497162240.00 | 186.58  \n",
      "                | LightGBM   | 7156     | 7959     | 20855277400785137664.00 | 189.53  \n",
      "---------------------------------------------------------------------------\n",
      "Peak Service    | Prophet    | 219      | 252      | 772050394695950080.00 | 199.83  \n",
      "                | SARIMA     | 214      | 250      | 745252862951630848.00 | 199.83  \n",
      "                | LightGBM   | 225      | 267      | 814240151961657600.00 | 199.82  \n",
      "---------------------------------------------------------------------------\n",
      "Rapid Route     | Prophet    | 14196    | 15205    | 11616157973122875392.00 | 199.55  \n",
      "                | SARIMA     | 9555     | 11243    | 9236396390693982208.00 | 199.32  \n",
      "                | LightGBM   | 13127    | 14656    | 11836084228716826624.00 | 199.44  \n",
      "---------------------------------------------------------------------------\n",
      "School          | Prophet    | 2173     | 2194     | 3569682260107949056.00 | 199.46  \n",
      "                | SARIMA     | 2977     | 3621     | 1403778690281119232.00 | 199.72  \n",
      "                | LightGBM   | 1276     | 1559     | 849545010945500160.00 | 199.25  \n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "Final Score -> Prophet: 0, SARIMA: 3, LightGBM: 2\n",
      ">>> OVERALL CHAMPION: SARIMA <<<\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Step 4: Final Model Comparison (Backtesting with Advanced Metrics) ---\")\n",
    "print(\"Evaluating forecast accuracy on the last 7 days of known data...\\n\")\n",
    "\n",
    "# Define Backtest Split\n",
    "test_horizon = 7\n",
    "train_df = df.iloc[:-test_horizon]\n",
    "test_df = df.iloc[-test_horizon:]\n",
    "\n",
    "results = []\n",
    "score = {'Prophet': 0, 'SARIMA': 0, 'LightGBM': 0}\n",
    "\n",
    "# Print Header\n",
    "print(f\"{'Service':<15} | {'Model':<10} | {'MAE':<8} | {'RMSE':<8} | {'MAPE':<8} | {'SMAPE':<8}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "for service in service_types:\n",
    "    y_train = train_df[service].astype(float)\n",
    "    y_test = test_df[service].astype(float)\n",
    "    \n",
    "    # ---------------- PROPHET ----------------\n",
    "    p_df = pd.DataFrame({'ds': y_train.index, 'y': y_train.values})\n",
    "    m_p = Prophet(growth='linear', seasonality_mode='multiplicative', weekly_seasonality=True)\n",
    "    m_p.fit(p_df)\n",
    "    future_p = m_p.make_future_dataframe(periods=test_horizon, include_history=False)\n",
    "    y_pred_p = m_p.predict(future_p)['yhat'].values\n",
    "    met_p = calculate_metrics(y_test, y_pred_p)\n",
    "    \n",
    "    # ---------------- SARIMA ----------------\n",
    "    try:\n",
    "        m_s = SARIMAX(y_train, order=(1, 1, 1), seasonal_order=(0, 1, 1, 7), \n",
    "                      enforce_stationarity=False, enforce_invertibility=False)\n",
    "        fit_s = m_s.fit(disp=False)\n",
    "        y_pred_s = fit_s.predict(start=len(y_train), end=len(y_train)+test_horizon-1).values\n",
    "        met_s = calculate_metrics(y_test, y_pred_s)\n",
    "    except:\n",
    "        met_s = {'RMSE': 999, 'MAE': 999, 'MAPE': 999, 'SMAPE': 999} # Penalty\n",
    "\n",
    "    # ---------------- LIGHTGBM ----------------\n",
    "    df_lgb = create_features(pd.DataFrame({'y': y_train}), label='y')\n",
    "    X_t = df_lgb.drop(columns=['y'])\n",
    "    y_t = df_lgb['y']\n",
    "    model_lgb = lgb.LGBMRegressor(n_estimators=100, verbose=-1)\n",
    "    model_lgb.fit(X_t, y_t)\n",
    "    \n",
    "    future_feats_lgb = []\n",
    "    for date in y_test.index:\n",
    "        hist_date = date - pd.Timedelta(days=7)\n",
    "        lag_val = y_train.loc[hist_date] if hist_date in y_train.index else 0\n",
    "        lag_14_val = y_train.loc[date - pd.Timedelta(days=14)] if (date - pd.Timedelta(days=14)) in y_train.index else 0\n",
    "        roll_mean = y_train.loc[date - pd.Timedelta(days=13):hist_date].mean()\n",
    "        future_feats_lgb.append({\n",
    "            'dayofweek': date.dayofweek, 'month': date.month, 'year': date.year, 'dayofyear': date.dayofyear,\n",
    "            'lag_7': lag_val, 'lag_14': lag_14_val, 'roll_mean_7': roll_mean\n",
    "        })\n",
    "    X_test_lgb = pd.DataFrame(future_feats_lgb)[X_t.columns]\n",
    "    y_pred_l = model_lgb.predict(X_test_lgb)\n",
    "    met_l = calculate_metrics(y_test, y_pred_l)\n",
    "\n",
    "    # --- Compare & Score ---\n",
    "    # We use MAE as the tie-breaker for the \"Winner\"\n",
    "    maes = {'Prophet': met_p['MAE'], 'SARIMA': met_s['MAE'], 'LightGBM': met_l['MAE']}\n",
    "    winner = min(maes, key=maes.get)\n",
    "    score[winner] += 1\n",
    "    \n",
    "    # Store full results\n",
    "    results.append({'Service': service, 'Model': 'Prophet', **met_p, 'Is_Winner': (winner=='Prophet')})\n",
    "    results.append({'Service': service, 'Model': 'SARIMA', **met_s, 'Is_Winner': (winner=='SARIMA')})\n",
    "    results.append({'Service': service, 'Model': 'LightGBM', **met_l, 'Is_Winner': (winner=='LightGBM')})\n",
    "\n",
    "    # Print Row per Model\n",
    "    print(f\"{service:<15} | {'Prophet':<10} | {met_p['MAE']:<8.0f} | {met_p['RMSE']:<8.0f} | {met_p['MAPE']:<8.2f} | {met_p['SMAPE']:<8.2f}\")\n",
    "    print(f\"{'':<15} | {'SARIMA':<10} | {met_s['MAE']:<8.0f} | {met_s['RMSE']:<8.0f} | {met_s['MAPE']:<8.2f} | {met_s['SMAPE']:<8.2f}\")\n",
    "    print(f\"{'':<15} | {'LightGBM':<10} | {met_l['MAE']:<8.0f} | {met_l['RMSE']:<8.0f} | {met_l['MAPE']:<8.2f} | {met_l['SMAPE']:<8.2f}\")\n",
    "    print(\"-\" * 75)\n",
    "\n",
    "print(f\"\\nFinal Score -> Prophet: {score['Prophet']}, SARIMA: {score['SARIMA']}, LightGBM: {score['LightGBM']}\")\n",
    "champion = max(score, key=score.get)\n",
    "print(f\">>> OVERALL CHAMPION: {champion} <<<\")\n",
    "\n",
    "# Save Detailed Log\n",
    "pd.DataFrame(results).to_csv('dashboard_data/log_model_comparison_full.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
